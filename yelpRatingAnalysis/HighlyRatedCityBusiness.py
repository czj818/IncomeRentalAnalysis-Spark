# -*- coding: utf-8 -*-
"""hw5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OjdktWufLmc8XAp-BkJrI22CsV3GbkNh
"""

import json
from pyspark import SparkContext
from pyspark.sql import *
sc = SparkContext.getOrCreate()

input_file = sc.textFile("hdfs:///data/umsi618f20/hw5/business.json")

def cat_info(data):
    cat_info_list = []
    city = data.get('city', None)
    stars = data.get('stars', None)
    num_review = data.get('review_count', None)
    categories_raw = data.get('categories', None)
    if categories_raw and city != None:
        categories = categories_raw.split(', ')
        for cat in categories:
            if num_review != None:
              if stars >=3:
                cat_info_list.append(((city, cat), (1, num_review,1)))
              else:
                cat_info_list.append(((city, cat), (1, num_review,0)))
    return cat_info_list


cat_stars = input_file.map(lambda line: json.loads(line)).flatMap(cat_info).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2])).sortByKey()


cat_stars.collect()
cat_stars.map(lambda t: t[0][0] + '\t' + t[0][1] + '\t' +str(t[1][0]) + '\t' +  str(t[1][1]) + '\t' + str(t[1][2])).saveAsTextFile("/tmp/new_output")

#spark-submit --master yarn --num-executors 16 --executor-memory 1g --executor-cores 2 HighlyRatedCityBusiness.py
#hadoop fs -getmerge new_output yelp_output.txt



